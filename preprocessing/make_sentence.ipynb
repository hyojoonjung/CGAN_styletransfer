{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "load_file=pd.read_csv('/home/hjjung/ailab/VAE/data/pandora/comments.csv', index_col=False)\n",
    "load_file = load_file['body']\n",
    "save_file=open('./output.txt','w')\n",
    "no_blank = False\n",
    "while True:\n",
    "    line = load_file.readline()\n",
    "    if line == \"\":\n",
    "        break\n",
    "    if line.strip() == \"\":\n",
    "        if no_blank:\n",
    "            continue\n",
    "        save_file.write(f\"{line}\")\n",
    "    else:\n",
    "        # print(line)\n",
    "        result_ = tokenizer.tokenize(line)\n",
    "        # print(result_)\n",
    "        result  = [ f\"{cur_line}\\n\" for cur_line in result_ ]\n",
    "        for save_line in result:\n",
    "            save_file.write(save_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            author                                               body\n",
      "0  MetricExpansion                    Those stats come from the test.\n",
      "1  MetricExpansion  [Echoing the comment I just made on a related ...\n",
      "2  MetricExpansion  But then we're not guaranteed to be talking ab...\n",
      "3  MetricExpansion  This includes TYPE_MENTION being rare, TYPE_ME...\n",
      "4  MetricExpansion                              That's great to hear!\n"
     ]
    }
   ],
   "source": [
    "## PANDORA ##\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/pandora/comments.csv', index_col=False, encoding='utf-8')\n",
    "\n",
    "new_df = {'author': [], 'body': []}\n",
    "\n",
    "for i in range(len(df)):\n",
    "    author = df['author'].iloc[i]\n",
    "    text = sent_tokenize(df['body'].iloc[i])\n",
    "    for sen in text:\n",
    "        new_df['body'].append(sen)\n",
    "        new_df['author'].append(author)\n",
    "\n",
    "new_df = pd.DataFrame(new_df)\n",
    "print(new_df.head())\n",
    "new_df.to_csv('line_comments.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                ID                                               TEXT cOPN  \\\n",
      "0  1997_504851.txt  Well, right now I just woke up from a mid-day ...    y   \n",
      "1  1997_504851.txt  It's sort of weird, but ever since I moved to ...    y   \n",
      "2  1997_504851.txt  I remember starting my homework in  10th grade...    y   \n",
      "3  1997_504851.txt       Of course it was easier, but I still did it.    y   \n",
      "4  1997_504851.txt  But when I moved here, the homework got a litt...    y   \n",
      "\n",
      "  cCON cEXT cAGR cNEU  \n",
      "0    n    n    y    y  \n",
      "1    n    n    y    y  \n",
      "2    n    n    y    y  \n",
      "3    n    n    y    y  \n",
      "4    n    n    y    y  \n"
     ]
    }
   ],
   "source": [
    "## ESSAY ##\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/essay.csv', index_col=False, encoding='utf-8')\n",
    "\n",
    "new_df = {'ID' : [], 'TEXT': [], 'cOPN': [], 'cCON': [], 'cEXT': [], 'cAGR': [], 'cNEU': []}\n",
    "\n",
    "for i in range(len(df)):\n",
    "    ID = df['#AUTHID'].iloc[i]\n",
    "    OPN = df['cOPN'].iloc[i]\n",
    "    CON = df['cCON'].iloc[i]\n",
    "    EXT = df['cEXT'].iloc[i]\n",
    "    AGR = df['cAGR'].iloc[i]\n",
    "    NEU = df['cNEU'].iloc[i]\n",
    "\n",
    "    text = sent_tokenize(df['TEXT'].iloc[i])\n",
    "    for sen in text:\n",
    "        new_df['ID'].append((ID))\n",
    "        new_df['TEXT'].append(sen)\n",
    "        new_df['cOPN'].append(OPN)\n",
    "        new_df['cCON'].append(CON)\n",
    "        new_df['cEXT'].append(EXT)\n",
    "        new_df['cAGR'].append(AGR)\n",
    "        new_df['cNEU'].append(NEU)\n",
    "\n",
    "new_df = pd.DataFrame(new_df)\n",
    "print(new_df.head())\n",
    "new_df.to_csv('line_essay.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen = \"How are you?\"\n",
    "s = sen.split()\n",
    "len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119203\n",
      "113035\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('line_essay.csv')\n",
    "drop_idx = []\n",
    "for i in range(len(df)):\n",
    "    text = df['TEXT'].iloc[i]\n",
    "    s = text.split()\n",
    "    if len(s) < 3:\n",
    "        drop_idx.append(i)\n",
    "\n",
    "new_df = df.drop(drop_idx)\n",
    "print(len(df))\n",
    "print(len(new_df))\n",
    "new_df.to_csv('new_essay.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/home/hjjung/ailab/VAE/data/pandora/line_ascii_null_dupli_comments.csv', index_col=False)\n",
    "df = df[['author', 'body']]\n",
    "df.to_csv('new_comments.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "510f147952a809ae0d7ce7416daaba05f3b4f42777e1cc4832d0fe55d94cfcb8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "510f147952a809ae0d7ce7416daaba05f3b4f42777e1cc4832d0fe55d94cfcb8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
